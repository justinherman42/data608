"0",""
"0",""
"0",""
"0",""
"0",""
"0",""
"0",""
"0","## use google api to convert cities into lat/long"
"0","## Due to costs I load in csv from query call"
"0","# api <- readLines(""E:\\Google_api.txt"")"
"0","# register_google(key = api)"
"0","locations_df2 <-read_csv(""geo_locations.csv"")    "
"0","locations_df2 <- locations_df2 %>% "
"0","    select(geo_state=state,city=City,lon,lat)"
"0",""
"0","joined_locations <- plyr::join(inc,locations_df2,'city')"
"0",""
"0","###Something went wrong with join, we have over 100k rows"
"0","### first step, drop duplicates"
"0","joined_locations <- unique(joined_locations)"
"0",""
"0","## now were down to 5900, lets see two "" nearly identical rows"""
"0","joined_locations[4,]==joined_locations[5,]"
"1","  "
"1"," Rank"
"1"," Name"
"1"," Growth_Rate"
"1"," Revenue"
"1"," Industry"
"1"," Employees"
"1"," City"
"1"," State"
"1"," state"
"1"," city"
"1"," geo_state"
"1","  lon"
"1","  lat"
"1","
32"
"1"," TRUE"
"1"," TRUE"
"1","        TRUE"
"1","    TRUE"
"1","     TRUE"
"1","      TRUE"
"1"," TRUE"
"1","  TRUE"
"1","  TRUE"
"1"," TRUE"
"1","     FALSE"
"1"," TRUE"
"1"," TRUE"
"1","
"
"0","## get rid of mismatches, google returned multiple when city could be in multiple states.  "
"0","## Easy fix I just said drop any row where google state is different from dataset state"
"0","joined_locations <- joined_locations %>% "
"0","    filter(geo_state==state)"
"0",""
"0","## print dim"
"0","dim(joined_locations)"
"1","[1]"
"1"," 5001"
"1","   13"
"1","
"
"0","##plot by location with size based on number employees"
"0","map<-get_map(location='united states', zoom=4, maptype = ""terrain"","
"0","             source='google',color='color')"
"0",""
"0","ggmap(map) + geom_point("
"0","        aes(x=lon, y=lat, show_guide = TRUE), "
"0","        data=joined_locations, alpha=.5, na.rm = T)  + "
"0","        scale_color_gradient(low=""beige"", high=""blue"")"
